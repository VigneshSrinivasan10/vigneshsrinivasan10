
<!-- saved from url=(0032)http://www.cs.berkeley.edu/~rbg/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<title>Vignesh Srinivasan</title>
<style type="text/css" media="screen">
html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}

a {
  color: #1772d0;
  text-decoration:none;
}

a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}

a.paper {
  font-weight: bold;
  font-size: 12pt;
}

b.paper {
  font-weight: bold;
  font-size: 12pt;
}

* {
  margin: 0pt;
  padding: 0pt;
}

body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 800px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #eee;
}

h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15pt;
  font-weight: 700;
}

h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  font-weight: 700;
}

strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
}

ul {
  list-style: circle;
  padding-top: 0.5em;
}

img {
  border: none;
}

li {
  padding-bottom: 0.4em;
  margin-left: 1.4em;
}

strong, b {
	font-weight:bold;
}

em, i {
	font-style:italic;
}

div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}

div.spanner {
  clear: both;
}

div.subsec {
  clear: both;
  margin-bottom: 0.1em;
  background: #fff;
  padding: 0.5em 0.5em 0.5em 0.5em;
}

div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 0.5em 0.5em 0.5em 0.5em;
}

div.paper div {
  padding-left: 200px;
}

img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 170px;
}

div.dissert {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}

div.dissert div {
  padding-left: 10px;
}

img.dissert {
  margin-bottom: 0.5em;
  float: left;
  width: 140px;
}

span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}

pre, code {
  margin: 0em 0;
  padding: 0;
}

div.paper pre {
  font-size: 1em;
}

</style>

<script type="text/javascript" async="" src="./page_files/ga.js"></script><script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-7953909-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-18061189-2', 'auto');
  ga('send', 'pageview');
</script>

<script type="text/javascript" src="./page_files/hidebib.js"></script>

<link href="./page_files/css" rel="stylesheet" type="text/css">
<!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>-->
<!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>-->
<!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
<style id="style-1-cropbar-clipper">/* Copyright 2014 Evernote Corporation. All rights reserved. */
.en-markup-crop-options {
    top: 18px !important;
    left: 50% !important;
    margin-left: -100px !important;
    width: 200px !important;
    border: 2px rgba(255,255,255,.7) solid !important;
    border-radius: 4px !important;
}

.en-markup-crop-options div div:first-of-type {
    margin-left: 0px !important;
}
</style></head>

<body>

<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 350px;">
  <div style="margin: 0 auto; line-height: 130%;">
    <img title="" style="float: right; padding-right: .1em;padding-left: .5em; height: 210px;" src="./images/vig_github_io.jpeg">
    <div style="padding-left: 1em; vertical-align: top; height: 3000px;">
      <span style="font-size: 25pt; line-height: 100%;">Vignesh Srinivasan</span><br><br>
      <span>
	I am an Applied  Scientist at Zalando Research in Berlin, Germany. My research interests include <b>score-based generative models</b> and robustness of deep neural networks. My current focus at Zalando is to work on innovative machine learning solutions to bypass the expensive process of fashion studio photography. I prototype the generation of high resolution <b>digital humans wearing curated outfits</b> using generative models like denoising diffusion probabilistic models.
	<br><br>		
	At Zalando, I work with <a href="https://de.linkedin.com/in/nikolay-jetchev-b623984b">Nikolay Jetchev</a> and <a href="https://de.linkedin.com/in/tnaghibi">Tofigh Naghibi</a>. Previously, I worked as a researcher at the Fraunhofer Heinrich Hertz Institute and Technische Universität Berlin with <a href="https://iphome.hhi.de/samek/">Wojciech Samek</a> and <a href="https://www.bifold.berlin/people/Ph.D._Shinichi_Nakajima.html">Shinichi Nakajima</a>. I received my PhD in machine learning under the supervision of <a href="https://www.ml.tu-berlin.de/menue/members/klaus-robert_mueller/">Prof. Dr. Klaus-Robert Müller</a>.  
	
</span>
<br><br>
      <!--<span><img src="./page_files/blabla.png"></img> / -->
	  vignesh.mssrinivasan [at] gmail.com | <a href="https://github.com/VigneshSrinivasan10/vigneshsrinivasan10.github.io/raw/761175e8a60f1ea2b2a4eab1ee4e06ad577dbc16/Papers/Vignesh_Srinivasan.pdf">Curriculum Vitae</a> | <a href="https://scholar.google.de/citations?user=2EwscoEAAAAJ&hl=en&oi=sra">Google scholar</a> | <a href="https://www.linkedin.com/in/vignesh-srinivasan-phd-95301192/">Linkedin</a> | <a href="http://github.com/VigneshSrinivasan10">Github</a> </span>
    </div>
  </div>
</div>

<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->
<div style="clear: both;">



<div class="section">
<h2 id="confpapers">Publications</h2>

<div class="section">
<h2 style="font-size: 15pt" id="confpapers">Score-based Generative Models & Robustness</h2>

<!--- TEMPLATE
<div class="paper" id="X">
  <img class="paper" title="X" src="images/X.png" />
  <div>
    <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'X-eccv-14']);" href="papers/X.pdf">X</a><br />
    <strong>Ross Girshick</strong> <br />
    European Conference on Computer Vision (ECCV), 2014<br /> /
    <a shape="rect" href="javascript:togglebib('X')" class="togglebib">bibtex</a></span>
    <pre xml:space="preserve">
@inproceedings{X,
  Author    = {X},
  Title     = {X},
  Booktitle = {Proceedings of the European
               Conference on Computer Vision ({ECCV})},
  Year      = {2014}}
    </pre>
    <span class="blurb">X</span>
  </div>
  <div class="spanner"></div>
</div>
-->

<div class="paper" id="srinivasan:diffashion2022">
  <img class="paper" title="ECCV 2022" src="./images/diffashion.png">
  <div>
    <a class="paper" href="">Diffusion Models for Outfit Rendering: Novel Conditioning Architectures for Subject-driven Generation</a><br>
      <strong>Vignesh Srinivasan</strong>, Nikolay Jetchev, Martin Heusel, Tofigh Naghibi<br>
      ECCV Workshops, 2022<br>      
  </pre>
  <span class="blurb">We propose novel conditioning architectures for diffusion models for generating curated outfits to be rendered on a digital human in predefined pose.</span>
  </div>
  <div class="spanner"></div>
</div>


<div class="paper" id="srinivasan:lcool2022">
  <img class="paper" title="PLOS ONE 2022" src="./images/lcool.png">
  <div>
    <a class="paper" href="https://ieeexplore.ieee.org/iel7/5962385/6104215/09707604.pdf">Langevin Cooling for Unsupervised Domain Translation</a><br>
      <strong>Vignesh Srinivasan</strong>, Klaus-Robert Müller, Wojciech Samek, Shinichi Nakajima<br>
      IEEE Transactions on Neural Networks and Learning Systems, 2022<br>

      [<a href="https://iphome.hhi.de/samek/bib/SriTNNLS22.bib.txt">bibtex</a>]
      [<a href="https://github.com/VigneshSrinivasan10/dr_pretraining">code</a>]
      
  </pre>
  <span class="blurb">We propose to perform Langevin dynamics on fringe samples to lower the temperature of test samples before applying the base domain translation method resulting in a significantly improved performance.</span>
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="srinivasan:malade">
  <img class="paper" title="NN 2021" src="./images/malade.jpg">
  <div>
    <a class="paper" href="https://www.sciencedirect.com/science/article/abs/pii/S0893608020304494">Robustifying Models Against Adversarial Attacks by Langevin Dynamics</a><br>
      <strong>Vignesh Srinivasan</strong>, Csaba Rohrer, Arturo Marban Klaus-Robert Müller, Wojciech Samek, Shinichi Nakajima<br>
      Neural Networks, 2021<br>

      [<a href="https://iphome.hhi.de/samek/bib/SriNN21.bib.txt">bibtex</a>]
      
  </pre>
  <span class="blurb">We introduce a generative model of the conditional distribution of the inputs given labels that can be learned through a supervised Denoising Autoencoder (sDAE) in alignment with a discriminative classifier. Our algorithm, called MALA for DEfense (MALADE) is applicable to any existing classifier, providing robust defense against adversarial as well as off-manifold samples. </span>
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="srinivasan:benign">
  <img class="paper" title="" src="./images/benign.png">
  <div>
    <a class="paper" href="https://ojs.aaai.org/index.php/AAAI/article/view/6042/5898">Benign examples: Imperceptible changes can enhance image translation performance</a><br>
      <strong>Vignesh Srinivasan</strong>, Klaus-Robert Müller, Wojciech Samek, Shinichi Nakajima<br>
      AAAI Conference on Artificial Intelligence, 2020<br>

      [<a href="https://iphome.hhi.de/samek/bib/SriAAAI20.bib.txt">bibtex</a>]
      
  </pre>
  <span class="blurb">We propose to perform Langevin dynamics, which makes a subtle change in the input space bringing them close to the data manifold, producing benign examples. The effect is significant improvement of the mapped image on the target domain.</span>
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="">
  <img class="paper" title="" src="./images/icmlw.png">
  <div>
    <a class="paper" href="https://iphome.hhi.de/samek/pdf/SriICML19.pdf">Defense against adversarial attacks by Langevin dynamics</a><br>
      <strong>Vignesh Srinivasan</strong>, Arturo Marban, Klaus-Robert Müller, Wojciech Samek, Shinichi Nakajima<br>
      ICML'19 Workshop on Uncertainty & Robustness in Deep Learning, 2019<br>

      [<a href="https://iphome.hhi.de/samek/bib/SriICML19.bib.txt">bibtex</a>]
      
  </pre>
  <span class="blurb"> </span>
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="">
  <img class="paper" title="" src="./images/levy.png">
  <div>
    <a class="paper" href="https://arxiv.org/pdf/1904.05586.pdf">Black-Box Decision based Adversarial Attack with Symmetric $\alpha$-stable Distribution</a><br>
      <strong>Vignesh Srinivasan</strong>, Ercan E Kuruoglu, Klaus-Robert Müller, Wojciech Samek, Shinichi Nakajima<br>
      European Signal Processing Conference (EUSIPCO), 2019<br>

      [<a href="https://iphome.hhi.de/samek/bib/SriEUSIPCO19.bib.txt">bibtex</a>]
      
  </pre>
  <span class="blurb">We investigate how statistics of random variables affect such random walk exploration. Specifically, we generalize the Boundary Attack, a state-of-the-art blackbox decision based attacking strategy, and propose the Levy-Attack, where the random walk is driven by symmetric $\alpha$-stable random variables.</span>
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="">
  <img class="paper" title="" src="./images/multi-kernel.png">
  <div>
    <a class="paper" href="">Multi-kernel prediction networks for denoising of burst images</a><br>
      Talmaj Marinč, <strong>Vignesh Srinivasan</strong>, Serhan Gül, Cornelius Hellge, Wojciech Samek<br>
      International Conference on Image Processing, 2019<br>

      [<a href="https://iphome.hhi.de/samek/bib/MarICIP19.bib.txt">bibtex</a>]
      
  </pre>
  <span class="blurb"> We propose a deep neural network based approach called Multi-Kernel Prediction Networks (MKPN) for burst image denoising.</span>
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="">
  <img class="paper" title="" src="./images/lrp_videos.png">
  <div>
    <a class="paper" href="">Interpretable human action recognition in compressed domain</a><br>
      <strong>Vignesh Srinivasan</strong>, Sebastian Lapuschkin, Cornelius Hellge, Klaus-Robert Müller, Wojciech Samek<br>
      International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2017<br>

      [<a href="https://iphome.hhi.de/samek/bib/SriICASSP17.bib.txt">bibtex</a>]
      
  </pre>
  <span class="blurb">We present a general method, Layer-wise Relevance Propagation (LRP), to understand and interpret action recognition algorithms and apply it to a state-of-the-art compressed domain method based on Fisher vector encoding and SVM classification.</span>
  </div>
  <div class="spanner"></div>
</div>


<div class="paper" id="">
  <img class="paper" title="" src="./images/euvip16.png">
  <div>
    <a class="paper" href="http://iphome.hhi.de/samek/pdf/SriEUVIP16.pdf"></a>On the robustness of action recognition methods in compressed and pixel domain<br>
      <strong>Vignesh Srinivasan</strong>, Serhan Gül, Sebastian Bosse, Jan Timo Meyer, Thomas Schierl, Cornelius Hellge, Wojciech Samek<br>
       European Workshop on Visual Information Processing (EUVIP), 2016<br>

      [<a href="https://iphome.hhi.de/samek/bib/SriEUVIP16.bib.txt">bibtex</a>]
      
  </pre>
<span class="blurb">This paper investigates the robustness of two state-of-theart action recognition algorithms.</span>
  </div>
  <div class="spanner"></div>
</div>


<div class="section">
<h2 style="font-size: 15pt" id="confpapers">AI for Health</h2>

<div class="paper" id="srinivasan:plosone2022">
  <img class="paper" title="PLOS ONE 2022" src="./images/dr_pretraining.png">
  <div>
    <a class="paper" href="https://arxiv.org/abs/2106.13497">To pretrain or not? A systematic analysis of the benefits of pretraining in diabetic retinopathy</a><br>
      <strong>Vignesh Srinivasan</strong>, Nils Strodthoff, Jackie Ma, Alexander Binder, Klaus-Robert Müller, Wojciech Samek<br>
      PLoS ONE, 2022<br>

      [<a href="https://iphome.hhi.de/samek/bib/SriPONE22.bib.txt">bibtex</a>]
      [<a href="https://github.com/VigneshSrinivasan10/dr_pretraining">code</a>]
      
  </pre>
  <span class="blurb">We investigate the effect of pretraining on downstream medical task using different aspects such as quantitative performance, statistics of the learned feature representations, interpretability and robustness to image distortions.</span>
  </div>
  <div class="spanner"></div>
</div>


<div class="paper" id="">
  <img class="paper" title="" src="./images/invisible.png">
  <div>
    <a class="paper" href="">Learning the Invisible: Limited Angle Tomography, Shearlets and Deep Learning</a><br>
      Tatiana A Bubba, Gitta Kutyniok, Matti Lassas, Maximilian März, Wojciech Samek, Samuli Siltanen, <strong>Vignesh Srinivasan</strong> <br>
      Inverse Problems, 2019<br>

      [<a href="https://iphome.hhi.de/samek/bib/BubInvPro19.bib.txt">bibtex</a>]
      
  </pre>
  <span class="blurb">We develop a hybrid reconstruction framework that fuses model-based sparse regularization with data-driven deep learning for the severely ill-posed inverse problem of limited angle computed tomography.</span>
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="">
  <img class="paper" title="" src="./images/marban1.png">
  <div>
    <a class="paper" href="https://arxiv.org/pdf/1805.08545.pdf">A recurrent convolutional neural network approach for sensorless force estimation in robotic surgery</a><br>
      Arturo Marban, <strong>Vignesh Srinivasan</strong>, Wojciech Samek, Josep Fernández, Alicia Casals<br>
      Biomedical Signal Processing and Control, 2019<br>

      [<a href="https://iphome.hhi.de/samek/bib/MarBSPC19.bib.txt">bibtex</a>]
      
  </pre>
  <span class="blurb">In this work, a force estimation model based on Convolutional Neural Networks and Long-Short Term Memory networks is proposed for Robot-Assisted Minimally Invasive Surgery.</span>
  </div>
  <div class="spanner"></div>
</div>



<div class="paper" id="">
  <img class="paper" title="" src="./images/marban2.png">
  <div>
    <a class="paper" href="https://upcommons.upc.edu/bitstream/handle/2117/132610/iros2018_paper_26_07_2018.pdf?sequence=3">Estimation of interaction forces in robotic surgery using a semi-supervised deep neural network model</a><br>
      Arturo Marban, <strong>Vignesh Srinivasan</strong>, Wojciech Samek, Josep Fernández, Alicia Casals<br>
      International Conference on Intelligent Robots and Systems (IROS), 2018<br>

      [<a href="https://iphome.hhi.de/samek/bib/MarIROS18.bib.txt">bibtex</a>]
      
  </pre>
  <span class="blurb">We investigate a model in a semi-supervised learning framework, consisting of an encoder network and a Long-Short Term Memory (LSTM) network to process unlabeled video sequences for vision-based force sensing in robotic surgery.</span>
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="">
  <img class="paper" title="" src="./images/marban3.png">
  <div>
    <a class="paper" href="http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w22/Marban_Estimating_Position__ICCV_2017_paper.pdf">Estimating position & velocity in 3d space from monocular video sequences using a deep neural network</a><br>
      Arturo Marban, <strong>Vignesh Srinivasan</strong>, Wojciech Samek, Josep Fernández, Alicia Casals<br>
      International Conference on Computer Vision Workshops, 2017<br>

      [<a href="https://iphome.hhi.de/samek/bib/MarICCVW17.bib.txt">bibtex</a>]
      
  </pre>
  <span class="blurb">This work describes a regression model based on Convolutional Neural Networks (CNN) and Long-Short Term Memory (LSTM) networks for tracking objects from monocular video sequences for the application of vision-based sensor substitution.</span>
  </div>
  <div class="spanner"></div>
</div>


<div class="section">
<h2 style="font-size: 15pt" id="confpapers">Others</h2>
  
<div class="paper" id="">
  <img class="paper" title="" src="./images/air_pollution.png">
  <div>
    <a class="paper" href="https://elib.dlr.de/137321/1/isprs-archives-XLIV-4-W2-2020-37-2020.pdf">Air Quality Monitoring and Data Management in Germany-Status Quo and Suggestions for Improvement</a><br>
      Lisanne Petry, Hendrik Herold, Gotthard Meinel, Thomas Meiers, Inken Müller, Elena Kalusche, Thilo Erbertseder, Hannes Taubenböck, Elaine Zaunseder, <strong>Vignesh Srinivasan</strong>, Ahmed Mohamed Magdi Mohamed Osman, Beatrix Weber, Stefan Jäger, Christian Mayer, Christian Gengenbach<br>
      The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 2020<br>

      [<a href="./Papers/airpollution.txt">bibtex</a>]
      
  </pre>
  <span class="blurb">This paper proposes a novel approach to facilitate air quality aware decision making and to support planning actors to take effective
measures for improving the air quality in cities and regions.</span>
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="">
  <img class="paper" title="" src="./images/hashcode.png">
  <div>
    <a class="paper" href="https://arxiv.org/pdf/1609.03219.pdf">Sharing hash codes for multiple purposes</a><br>
      Wiktor Pronobis, Danny Panknin, Johannes Kirschnick, <strong>Vignesh Srinivasan</strong>, Wojciech Samek, Volker Markl, Manohar Kaul, Klaus-Robert Müller, Shinichi Nakajima<br>
      Japanese Journal of Statistics and Data Science, 2018<br>

      [<a href="https://iphome.hhi.de/samek/bib/ProJJSD18.bib.txt">bibtex</a>]
      
  </pre>
  <span class="blurb">We propose multiple purpose LSH (mp-LSH) which shares the hash codes for different dissimilarities, where the weights can be adjusted at query time. </span>
  </div>
  <div class="spanner"></div>
</div>


<div class="paper" id="">
  <img class="paper" title="" src="./images/eusipco2015.png">
  <div>
    <a class="paper" href="https://hal.inria.fr/hal-01164350/document">Shot aggregating strategy for near-duplicate video retrieval</a><br>
      <strong>Vignesh Srinivasan</strong>, Frederic Lefebvre, Alexey Ozerov<br>
       European Signal Processing Conference (EUSIPCO), 2015<br>

      [<a href="Paprs/eusipco2015.txt">bibtex</a>]
      
  </pre>
<span class="blurb">We propose a new strategy for near-duplicate video retrieval that is based on shot aggregation.</span>
  </div>
  <div class="spanner"></div>
</div>


<div class="paper" id="">
  <div>
    <a class="paper" href="https://hal.inria.fr/hal-01164350/document">Shot aggregating strategy for near-duplicate video retrieval</a><br>
      Tim LM van Kasteren, Birte Ulrich, <strong>Vignesh Srinivasan</strong>, Maria E Niessen<br>
       European Conference on Information Retrieval, 2014<br>

      [<a href="Paprs/ecir2014.txt">bibtex</a>]
      
  </pre>
<span class="blurb">We analyze Twitter data that was captured around fifteen real world safety and
security events and use a number of analytical tools to help understand
the effectiveness of certain features for event detection and to study how
this data can be used to aid situational awareness.</span>
  </div>
  <div class="spanner"></div>
</div>


<div class="section">
<a name="dissertation"></a>
<h2>Doctoral Thesis</h2>

<div class="dissert" id="Srinivasan:PhD12">
  <div>
    <a class="paper" href="https://depositonce.tu-berlin.de/bitstream/11303/16187/7/srinivasan_vignesh.pdf">Towards robustifying deep neural networks against adversarial, fringe and distorted examples</a><br>
    <strong>V. Srinivasan</strong><br>
    Ph.D. dissertation, Technische Universität Berlin, 2021<br>
    [<a href="https://scholar.googleusercontent.com/scholar.bib?q=info:nJHXqcnMN60J:scholar.google.com/&output=citation&scisdr=CgXYichdEJmnrtgUgiQ:AAGBfm0AAAAAY0gSmiRxBUllhJSMvs-aECeIezaq86pi&scisig=AAGBfm0AAAAAY0gSmriPDaZij3HuSAp_RdTPiD260US-&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1">bibtex</a>]

    </pre>
    <span class="blurb">Evaluators: <a href="https://www.ml.tu-berlin.de/menue/members/klaus-robert_mueller/">Prof. Dr. Klaus-Robert Müller</a>, <a href="https://www.dbs.ifi.lmu.de/~tresp/">Prof. Dr. Volker Tresp</a> and <a href="https://anhnguyen.me/research/">Prof. Dr. Anh Nguyen</a></span>
  </div>
  <div class="spanner"></div>
  <br>
</div>

</div>

</div>


<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>




</body></html>
